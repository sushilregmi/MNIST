{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-04T15:35:45.204983Z","iopub.execute_input":"2022-06-04T15:35:45.205363Z","iopub.status.idle":"2022-06-04T15:35:45.212921Z","shell.execute_reply.started":"2022-06-04T15:35:45.205334Z","shell.execute_reply":"2022-06-04T15:35:45.211941Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"# Implementing with keras library\n","metadata":{}},{"cell_type":"code","source":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense,Flatten, BatchNormalization,Conv2D,MaxPooling2D,Dropout\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:14:54.425725Z","iopub.execute_input":"2022-06-04T16:14:54.426152Z","iopub.status.idle":"2022-06-04T16:14:54.431465Z","shell.execute_reply.started":"2022-06-04T16:14:54.426114Z","shell.execute_reply":"2022-06-04T16:14:54.430515Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"markdown","source":"# Loading train and test datasets","metadata":{}},{"cell_type":"code","source":"\ntrain = pd.read_csv(\"../input/digit-recognizer/train.csv\")\ntrain.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:14:59.181381Z","iopub.execute_input":"2022-06-04T16:14:59.182381Z","iopub.status.idle":"2022-06-04T16:15:01.491485Z","shell.execute_reply.started":"2022-06-04T16:14:59.182339Z","shell.execute_reply":"2022-06-04T16:15:01.490533Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:15:05.355559Z","iopub.execute_input":"2022-06-04T16:15:05.356847Z","iopub.status.idle":"2022-06-04T16:15:05.377465Z","shell.execute_reply.started":"2022-06-04T16:15:05.356801Z","shell.execute_reply":"2022-06-04T16:15:05.376529Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"\ntest = pd.read_csv(\"../input/digit-recognizer/test.csv\")\ntest","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:15:08.380429Z","iopub.execute_input":"2022-06-04T16:15:08.380812Z","iopub.status.idle":"2022-06-04T16:15:09.774133Z","shell.execute_reply.started":"2022-06-04T16:15:08.380782Z","shell.execute_reply":"2022-06-04T16:15:09.773190Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":"The datasets contains total of 70,000 images with 784 pixel values for each images.\nSince we are applying CNN ( Convolutional Neural Network ), the input for the model must be in the form of 4D array. So we convert the pixel values to 4D array.\nWe obtain the image with 28 * 28 size with only one channel, since the images are in grayscale.","metadata":{}},{"cell_type":"code","source":"X = train.drop(columns = 'label')\ny = train['label']\nX = X.to_numpy(dtype='float32').reshape((42000,28,28,1))\n\nX.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:15:11.999044Z","iopub.execute_input":"2022-06-04T16:15:11.999846Z","iopub.status.idle":"2022-06-04T16:15:12.195412Z","shell.execute_reply.started":"2022-06-04T16:15:11.999804Z","shell.execute_reply":"2022-06-04T16:15:12.194424Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:15:24.454929Z","iopub.execute_input":"2022-06-04T16:15:24.455339Z","iopub.status.idle":"2022-06-04T16:15:24.461565Z","shell.execute_reply.started":"2022-06-04T16:15:24.455303Z","shell.execute_reply":"2022-06-04T16:15:24.460673Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"markdown","source":"We then normalze the pixel values in between the range of 0 and 1, since the computation becomes faster if the inputs are normalized.","metadata":{}},{"cell_type":"code","source":"X = X/255.0\nplt.figure(figsize=(15,15)) \nsns.heatmap(X[9].reshape(28,28), annot= True, cmap=\"binary\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:15:15.014911Z","iopub.execute_input":"2022-06-04T16:15:15.015729Z","iopub.status.idle":"2022-06-04T16:15:17.625289Z","shell.execute_reply.started":"2022-06-04T16:15:15.015686Z","shell.execute_reply":"2022-06-04T16:15:17.624309Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"markdown","source":"We perform one hot encoding to the class labels using to_categorical from keras library.","metadata":{}},{"cell_type":"code","source":"y = to_categorical(y,num_classes = 10)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:35:51.750218Z","iopub.execute_input":"2022-06-04T15:35:51.750522Z","iopub.status.idle":"2022-06-04T15:35:51.754854Z","shell.execute_reply.started":"2022-06-04T15:35:51.750495Z","shell.execute_reply":"2022-06-04T15:35:51.753975Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(X,y,test_size=0.3,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:35:51.756079Z","iopub.execute_input":"2022-06-04T15:35:51.756418Z","iopub.status.idle":"2022-06-04T15:35:52.120359Z","shell.execute_reply.started":"2022-06-04T15:35:51.756391Z","shell.execute_reply":"2022-06-04T15:35:52.119293Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"X_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:35:52.121882Z","iopub.execute_input":"2022-06-04T15:35:52.122217Z","iopub.status.idle":"2022-06-04T15:35:52.128062Z","shell.execute_reply.started":"2022-06-04T15:35:52.122188Z","shell.execute_reply":"2022-06-04T15:35:52.127164Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"X_train","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:02:20.974845Z","iopub.status.idle":"2022-06-04T16:02:20.975229Z","shell.execute_reply.started":"2022-06-04T16:02:20.975036Z","shell.execute_reply":"2022-06-04T16:02:20.975053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3), padding='same', input_shape=(28, 28, 1), activation='relu'))\nmodel.add(Conv2D(32, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.1))\n\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(64, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.3))\n\nmodel.add(Conv2D(256, (3,3), padding='same', activation='relu'))\nmodel.add(Conv2D(256, (3,3), padding='same', activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(Dropout(0.4))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(10, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:35:52.130417Z","iopub.execute_input":"2022-06-04T15:35:52.130815Z","iopub.status.idle":"2022-06-04T15:35:52.299642Z","shell.execute_reply.started":"2022-06-04T15:35:52.130774Z","shell.execute_reply":"2022-06-04T15:35:52.298807Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:35:52.300749Z","iopub.execute_input":"2022-06-04T15:35:52.301028Z","iopub.status.idle":"2022-06-04T15:35:52.308499Z","shell.execute_reply.started":"2022-06-04T15:35:52.301002Z","shell.execute_reply":"2022-06-04T15:35:52.307405Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"Altogether we have used \nConvolution layer = 8 \nBatch normaliation layer = 4\nMax pooling layer = 4\ndropout layer = 4\nflattern layer = 1\ndense(fully connected layer) = 2\n\n1. Convolution layer with various filters for extracting differnet features of image are used with size of 3 * 3 pixels. Padding = 'same' is used for adding the zero padding by 1 pixels in each side. The input and output size remains same if we apply the stride size of 1 in padding = 'same' case. The activation function relu is used to introduce the non linearity in the pixels values. It removes the linear component created by shadows in the image.\n\n2. Batch normalization layer are used to speed up the training and to use the higher learning rate. It is done within the value of a individual neuron.\n\n3. Max pooling layer is used to reduce the dimensionality of feature maps without losing the information. As a feature map becomes small, it becomes increasingly independent of the location of the feature.\n\n4. Dropout layer is used to nullify the contribution of some neurons toward the next layer and leaves unmodified all others. They are important in training CNNs because they prevent overfitting on the training data.\n\n5. Flatten layer rehshape the feature maps dimensions to have a dimesnion of one with the number of elements equal to the number of elements in the feature maps.\nFor (None,4,4,512) ----(flatten)----- (None,8192)\n\n6. Dense layer is that layer that is deeply connected with its preceding layer which means the neurons of the layer are connected to every neuron of its preceding layer.","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = 'Adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:35:52.310026Z","iopub.execute_input":"2022-06-04T15:35:52.310669Z","iopub.status.idle":"2022-06-04T15:35:52.326345Z","shell.execute_reply.started":"2022-06-04T15:35:52.310625Z","shell.execute_reply":"2022-06-04T15:35:52.325177Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"We used the optimzer 'Adam' since it automatically tune the learning rate.\nThe loss function used is categorical cross entropy which is calculated for each class label as - log(predicted probability of that class).","metadata":{}},{"cell_type":"code","source":"training = model.fit(X_train,y_train,validation_data=(X_val,y_val),batch_size=128,epochs=25,verbose = 0)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T15:35:52.327459Z","iopub.execute_input":"2022-06-04T15:35:52.328132Z","iopub.status.idle":"2022-06-04T16:02:12.505397Z","shell.execute_reply.started":"2022-06-04T15:35:52.328098Z","shell.execute_reply":"2022-06-04T16:02:12.504204Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"Epochs: One epoch is finished when the network has seen the whole dataset.\n\nBatch size: The number of examples used to train the network for a forward and backward pass. \n\nExample: \n\nnumber of training examples: 29400\n\nbatch size : 128\n\nnumber of iteration to complete one epoch = 29400/128 = 230","metadata":{}},{"cell_type":"code","source":"loss = model.evaluate(X_val, y_val,verbose = 2)\nprint(\"Val Loss\", loss[0])\nprint(\"Val Accuracy\", loss[1])","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:02:12.506971Z","iopub.execute_input":"2022-06-04T16:02:12.507796Z","iopub.status.idle":"2022-06-04T16:02:20.933233Z","shell.execute_reply.started":"2022-06-04T16:02:12.507757Z","shell.execute_reply":"2022-06-04T16:02:20.932170Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:11:44.778259Z","iopub.execute_input":"2022-06-04T16:11:44.778688Z","iopub.status.idle":"2022-06-04T16:11:44.812984Z","shell.execute_reply.started":"2022-06-04T16:11:44.778652Z","shell.execute_reply":"2022-06-04T16:11:44.812017Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:15:32.173317Z","iopub.execute_input":"2022-06-04T16:15:32.173725Z","iopub.status.idle":"2022-06-04T16:15:32.179499Z","shell.execute_reply.started":"2022-06-04T16:15:32.173690Z","shell.execute_reply":"2022-06-04T16:15:32.178832Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"test = test.to_numpy(dtype='float32').reshape((28000,28,28,1))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:15:40.421821Z","iopub.execute_input":"2022-06-04T16:15:40.422265Z","iopub.status.idle":"2022-06-04T16:15:40.471110Z","shell.execute_reply.started":"2022-06-04T16:15:40.422229Z","shell.execute_reply":"2022-06-04T16:15:40.469992Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"test.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:15:50.359609Z","iopub.execute_input":"2022-06-04T16:15:50.360012Z","iopub.status.idle":"2022-06-04T16:15:50.365334Z","shell.execute_reply.started":"2022-06-04T16:15:50.359980Z","shell.execute_reply":"2022-06-04T16:15:50.364630Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"predictions = np.argmax(model.predict(test,verbose=0),axis=-1)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:21:54.114312Z","iopub.execute_input":"2022-06-04T16:21:54.114804Z","iopub.status.idle":"2022-06-04T16:22:13.845177Z","shell.execute_reply.started":"2022-06-04T16:21:54.114769Z","shell.execute_reply":"2022-06-04T16:22:13.844197Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"predictions\n","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:30:13.562132Z","iopub.execute_input":"2022-06-04T16:30:13.562526Z","iopub.status.idle":"2022-06-04T16:30:13.569553Z","shell.execute_reply.started":"2022-06-04T16:30:13.562495Z","shell.execute_reply":"2022-06-04T16:30:13.568584Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"submission.csv\", index=False, header=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:30:36.972699Z","iopub.execute_input":"2022-06-04T16:30:36.973129Z","iopub.status.idle":"2022-06-04T16:30:37.014600Z","shell.execute_reply.started":"2022-06-04T16:30:36.973078Z","shell.execute_reply":"2022-06-04T16:30:37.013576Z"},"trusted":true},"execution_count":96,"outputs":[]}]}